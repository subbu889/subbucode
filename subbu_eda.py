# -*- coding: utf-8 -*-
"""subbu EDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kxnF8ZePrgpgIRssd3qpB4SYVIUqKGqW
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

car1 = pd.read_csv("/content/tc20171021.csv",on_bad_lines='skip')
car2 = pd.read_csv("/content/true_car_listings.csv")

car1.shape

car1.head()

car2.head()

car1.isnull().sum()

car2.isnull().sum()

car1.info()

#Drop the missing values â€“ If the dataset is huge and missing values are very few then we can directly drop the values because it will not have much impact
#preprocessing of data

car1.drop(columns = ["Id"], inplace = True)

car1.head(8)

#merging the data

cars = pd.concat([car1, car2], ignore_index=True)

cars.head(6)

cars.info()

cars.isnull().sum()

#statstical analysis

#descreptive analysis

#numerical varibles

for i in cars.columns.to_list():
    if str(cars[i].dtype) == 'int64':
        # Print Statistics of it
        print("Descriptive Statistics is for columns {} :\n {}".format(i, cars[i].describe()))
        fig, ax = plt.subplots(2,1, figsize = (8,12))
        ax[0].set_title(f"Box Plot For Columns {i}")
        ax[0].boxplot(cars[i], vert = False, sym = "r.")
        ax[1].set_title(f"Histogram of values for column {i}")
        r = ax[1].hist(cars[i], histtype = "bar")
        ax[1].set_ylim(top = np.max(r[0]) + 10)
        plt.show()

# Removig outliers in milage columns using the 1.5 inter quartile range
mile_iqr    = (cars["Mileage"].describe()["75%"] - cars["Mileage"].describe()["25%"])
mile_iqr_15 = 1.5*mile_iqr
mile_iqr_3  = 3*mile_iqr
# Inner and outer  Lower fences:
lower_inner = cars["Mileage"].describe()["25%"] - mile_iqr_15
lower_outer = cars["Mileage"].describe()["25%"] - mile_iqr_3
# Inner and outer  Upper fences:
upper_inner = cars["Mileage"].describe()["75%"] + mile_iqr_15
upper_outer = cars["Mileage"].describe()["75%"] + mile_iqr_3
# Severe Outlies are those points which not between the two outer:

mile_iqr

otliers_index = cars[(cars["Mileage"] <= lower_outer) | (cars["Mileage"] >= upper_outer)].index

cars.drop(otliers_index, inplace = True)

cars.head()







#Agian Plotting mileage:
i = "Mileage"
print("Descriptive Statistics is for columns {} :\n {}".format(i, cars[i].describe()))
fig, ax = plt.subplots(2,1, figsize = (10,10))
ax[0].set_title(f"Box Plot For Columns {i}")
ax[0].boxplot(cars[i], vert = False, sym = "r.")
ax[1].set_title(f"Histogram of values for column {i}")
r = ax[1].hist(cars[i], histtype = "bar")
ax[1].set_ylim(top = np.max(r[0]) + 10)
plt.show()

cars["Usage_level"].value_counts()

for i in cars.columns.to_list():
    if str(cars[i].dtype) == 'object':
        print(f" ============ Categorical Columns {i} ===========")
        print(f" ============ Unique Values ===========")
        print(cars[i].unique())
        print(f" ============ Value Counts ===========")
        print(cars[i].value_counts())

# VIN Column Have some duplicates which is note allowed as each motor has only one IN
repeated_vin = cars["Vin"].value_counts()[cars["Vin"].value_counts() > 1].index

random_repeated = np.random.choice(repeated_vin, size = 80)
for vin in random_repeated:
    print(f"======= Repeated VIN {vin}")
    print(cars[cars["Vin"] == vin])

#Removing Duplicate VINs
cars.drop_duplicates(subset = "Vin", inplace= True)

#Checking subset of dropped duplicates
for vin in random_repeated:
    print(f"======= Repeated VIN {vin}")
    print(cars[cars["Vin"] == vin])

cars["Model"] = cars["Model"].apply(upper_states)

df_full["Model"] = df_full["Model"].apply(upper_states)

cars["City"].value_counts()[cars["City"].value_counts() < 100]

cars[cars["Year"] < 2006].shape

cars.shape

df_old = cars[cars["Year"] < 2006]

df_new = cars[cars["Year"] >= 2006]

cars.drop(cars[cars["Mileage"] < 10].index, inplace = True)

cars = cars.reset_index().drop(columns = ["index"])

cars.drop(columns = ["Vin"], inplace = True)

def get_mile_range(mileage):
    if mileage < 25000:
        return "Low"
    elif (25000 <= mileage) and (mileage < 80000 ):
        return "Medium"
    else:
        return "High"

cars["Usage_level"] = cars["Mileage"].apply(get_mile_range)

def city_importance(city):
    important_cities = ["New York", "Los Angeles", "Chicago", "Houston", "Phoenix", "Philadelphia",
                        "San Antonio", "San Diego", "Dallas", "San Jose"]
    Midium_cities = ["Austin", "Jacksonville", "Fort Worth", "Columbus", "Charlotte", "San Francisco",
                     "Indianapolis", "Seattle", "Denver", "Washington"]
    important_cities = [c.upper() for c in important_cities]
    Midium_cities = [c.upper() for c in Midium_cities]
    if city in important_cities:
        return "High"
    elif city in Midium_cities:
        return "Medium"
    else:
        return "Low"

cars["City_imporatnce"] = cars["City"].apply(city_importance)

#Plotting Usage Level:
i = "Usage_level"
plt.figure(figsize = (10,10))
plt.title(f"Histogram of values for column {i}")
sns.countplot(x= cars[i])
plt.ylim(top = np.max(r[0]) + 10)
plt.show()

#Plotting Usage Level:
i = "City_imporatnce"
plt.figure(figsize = (10,10))
plt.title(f"Histogram of values for column {i}")
sns.countplot(x= cars[i])
plt.ylim(top = np.max(r[0]) + 600000)
plt.show()

new_cities = df_new.City.value_counts()[:10]

new_cities.at["Other_cities"] = df_new.City.value_counts()[10:].sum()

df_old.City.value_counts()[:10]

old_cities = df_old.City.value_counts()[:10]
old_cities.at["Other_cities"] = df_old.City.value_counts()[10:].sum()

plt.title("Old Cars Cities' Distribution", pad= 120, fontsize = 25)
plt.pie(old_cities[:-1], labels = old_cities.index[:-1], shadow = True, radius = 1.5, 
       rotatelabels= True)
plt.show()

plt.title("New Cars Cities' Distribution", pad= 120, fontsize = 25)

plt.pie(new_cities[:-1], labels = new_cities.index[:-1], shadow = True, radius = 1.5, 
       rotatelabels= True)
plt.show()



